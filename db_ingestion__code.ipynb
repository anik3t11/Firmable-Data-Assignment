{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bH4GFprW2zTl"
      },
      "outputs": [],
      "source": [
        "#Library required\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import os\n",
        "import json\n",
        "from google.cloud import bigquery\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# connecting notebook with gdrive to access the dataset (I have uploaded to my g drive)\n",
        "#folder_path = '/content/drive/MyDrive/pran-project-470608-2f7bfba6b03c.json'\n",
        "\n",
        "# Read service account key\n",
        "folder_path ='' # copy the JSOn key path here to connect with Big query\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "siLCFY-x27ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Path to access the dataset to gdrive\n",
        "folder = Path(\"/content/drive/MyDrive/Datasets-2025-08-08\")\n",
        "files = sorted(folder.glob(\"*.jsonl\"))"
      ],
      "metadata": {
        "id": "1NLjSf7J27s6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Code to Flatten the JSONl data\n",
        "\n",
        "to_list = lambda x: [] if x is None else (x if isinstance(x, list) else [x])\n",
        "\n",
        "all_data, inc_company, inc_article = [], [], [] #Diffent list to store diffent set of arrays\n",
        "\n",
        "# for fp in files:\n",
        "#     with fp.open() as f:\n",
        "#         for line in f:\n",
        "#             obj = json.loads(line)\n",
        "#             all_data += to_list(obj.get(\"data\"))\n",
        "#             all_inc  += to_list(obj.get(\"included\"))\n",
        "\n",
        "for fp in files:\n",
        "    with fp.open() as f:\n",
        "        for line in f:\n",
        "            obj = json.loads(line)\n",
        "\n",
        "            # grab data as usual\n",
        "            all_data += to_list(obj.get(\"data\"))\n",
        "\n",
        "            # split included into 2 buckets\n",
        "            for inc in to_list(obj.get(\"included\")):\n",
        "                if inc.get(\"type\") == \"company\":\n",
        "                    inc_company.append(inc)\n",
        "                elif inc.get(\"type\") == \"news_article\":\n",
        "                    inc_article.append(inc)\n",
        "\n",
        "\n",
        "#Normalizing data to get data in row and column format\n",
        "df_data       = pd.json_normalize(all_data, sep=\".\")\n",
        "df_included_1 = pd.json_normalize(inc_company, sep=\".\")     # companies\n",
        "df_included_2 = pd.json_normalize(inc_article, sep=\".\")\n",
        "\n",
        "#to get size of df we generated\n",
        "print(\"data rows:\", len(df_data), \"| included rows:\", len(df_included_1), \"| included2 rows:\", len(df_included_2))"
      ],
      "metadata": {
        "id": "yuOgPywv27z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to count the id in case of duplicacy\n",
        "df_included_1['id'].value_counts()"
      ],
      "metadata": {
        "id": "qTkUyk13276D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_included_1[df_included_1['id'] == '7b7dbf17-a2ad-54cc-ac66-20995d7f6fba']"
      ],
      "metadata": {
        "id": "OJxaASwK27_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping the duplicate rows if any\n",
        "df_included_1 = df_included_1.drop_duplicates()\n",
        "df_included_1"
      ],
      "metadata": {
        "id": "xC3ch9LC28EJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_included_2 = df_included_2.drop_duplicates()\n",
        "df_included_2"
      ],
      "metadata": {
        "id": "eeJQOepOtRZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_included_1['id'].value_counts()"
      ],
      "metadata": {
        "id": "yueBbA4X28Ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_data.columns.tolist()"
      ],
      "metadata": {
        "id": "UlIJFpHx4V-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_data.head(4)"
      ],
      "metadata": {
        "id": "dbsa4rk55EZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cleaning the column names\n",
        "\n",
        "df_data.rename(columns = {\n",
        "    'attributes.summary':'summary',\n",
        " 'attributes.category':'category',\n",
        " 'attributes.found_at':'found_date',\n",
        " 'attributes.confidence':'confidence_score',\n",
        " 'attributes.article_sentence':'article_sentence',\n",
        " 'attributes.human_approved':'human_approved',\n",
        " 'attributes.planning':'planning',\n",
        " 'attributes.amount':'amount',\n",
        " 'attributes.amount_normalized':'amount_normalized',\n",
        " 'attributes.assets':'assets',\n",
        " 'attributes.assets_tags':'assets_tags',\n",
        " 'attributes.award':'award',\n",
        " 'attributes.contact':'contact',\n",
        " 'attributes.division':'division',\n",
        " 'attributes.effective_date':'effective_date',\n",
        " 'attributes.event':'event',\n",
        " 'attributes.financing_type':'financing_type',\n",
        " 'attributes.financing_type_normalized':'financing_type_normalized',\n",
        " 'attributes.financing_type_tags':'financing_type_tags',\n",
        " 'attributes.headcount':'headcount',\n",
        " 'attributes.job_title':'job_title',\n",
        " 'attributes.job_title_tags':'job_title_tags',\n",
        " 'attributes.location':'location',\n",
        " 'attributes.location_data':'location_data',\n",
        " 'attributes.product':'product',\n",
        " 'attributes.product_data.full_text':'product_full_text',\n",
        " 'attributes.product_data.name':'product_name',\n",
        " 'attributes.product_data.release_type':'product_release_type',\n",
        " 'attributes.product_data.release_version':'product_release_version',\n",
        " 'attributes.product_data.fuzzy_match':'product_fuzzy_match',\n",
        " 'attributes.product_tags':'product_tags',\n",
        " 'attributes.recognition':'recognization',\n",
        " 'attributes.vulnerability':'vulnerability',\n",
        " 'relationships.company1.data.id':'relationship_company1_id',\n",
        " 'relationships.company1.data.type':'relationship_company1_type',\n",
        " 'relationships.most_relevant_source.data.id':'relationship_most_relevant_id',\n",
        " 'relationships.most_relevant_source.data.type':'relationship_most_relevant_type',\n",
        " 'relationships.company2.data.id':'relationship_company2_id',\n",
        " 'relationships.company2.data.type':'relationship_company2_type'\n",
        "},inplace=True)"
      ],
      "metadata": {
        "id": "EHyr7RIY4kRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_data"
      ],
      "metadata": {
        "id": "-o_HpLEW7pZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_company_details = df_included_1\n",
        "df_company_details.columns.tolist()"
      ],
      "metadata": {
        "id": "4RSFLvjg7rFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_company_details.rename(columns = {\n",
        "    'attributes.domain':'domain',\n",
        "    'attributes.company_name':'company_name',\n",
        " 'attributes.ticker':'ticker'\n",
        "                          },inplace=True)"
      ],
      "metadata": {
        "id": "lT7ysLqv79b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_company_details.head(2)"
      ],
      "metadata": {
        "id": "izokFQnm8XqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_details = df_included_2\n",
        "df_details.columns.tolist()"
      ],
      "metadata": {
        "id": "EHeMPGsN8e96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_details.rename(columns = {\n",
        "     'attributes.author':'author',\n",
        " 'attributes.body':'body',\n",
        " 'attributes.image_url':'image_url',\n",
        " 'attributes.url':'url',\n",
        " 'attributes.published_at':'published_at',\n",
        " 'attributes.title':'title'\n",
        "                          },inplace=True)\n",
        "df_details"
      ],
      "metadata": {
        "id": "WOjGftsW8n4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_data.dtypes"
      ],
      "metadata": {
        "id": "yCVctUgu88yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#correcting the datatype where required\n",
        "df_data[\"found_date\"] = pd.to_datetime(df_data[\"found_date\"])\n",
        "df_data[\"effective_date\"] = pd.to_datetime(df_data[\"effective_date\"])\n",
        "df_data.info()"
      ],
      "metadata": {
        "id": "EY47ODpl9Vy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_company_details.info()"
      ],
      "metadata": {
        "id": "1li9ToFr97Wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_details.info()"
      ],
      "metadata": {
        "id": "Hw0VkSP0_XTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_details[\"published_at\"] = pd.to_datetime(df_details[\"published_at\"])\n",
        "df_details.info()"
      ],
      "metadata": {
        "id": "rOIm63pL_dU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Connecting big query to Notebook\n",
        "client = bigquery.Client.from_service_account_json(folder_path)"
      ],
      "metadata": {
        "id": "9ywqXVDaAVMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DDL command to create the new table where we will be strong the data\n",
        "\n",
        "query1 = \"\"\"\n",
        "CREATE TABLE firmable.article_details (\n",
        "    id STRING NOT NULL,\n",
        "    type STRING,\n",
        "    author STRING,\n",
        "    body STRING,\n",
        "    image_url STRING,\n",
        "    url STRING,\n",
        "    published_at TIMESTAMP,\n",
        "    title STRING\n",
        ");\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "result = client.query(query1).to_dataframe()\n"
      ],
      "metadata": {
        "id": "3pPcSAH1Ajfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query2 = \"\"\"\n",
        "CREATE TABLE firmable.company_details (\n",
        "    id STRING NOT NULL,\n",
        "    type STRING,\n",
        "    domain STRING,\n",
        "    company_name STRING,\n",
        "    ticker STRING\n",
        ");\n",
        "\n",
        "\"\"\"\n",
        "result = client.query(query2).to_dataframe()\n"
      ],
      "metadata": {
        "id": "mphfgjpcA3X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query3 = \"\"\"\n",
        "CREATE TABLE firmable.data_table (\n",
        "    id STRING NOT NULL,\n",
        "    type STRING,\n",
        "    summary STRING,\n",
        "    category STRING,\n",
        "    found_date TIMESTAMP,\n",
        "    confidence_score FLOAT64,\n",
        "    article_sentence STRING,\n",
        "    human_approved BOOL,\n",
        "    planning BOOL,\n",
        "    amount STRING,\n",
        "    amount_normalized FLOAT64,\n",
        "    assets STRING,\n",
        "    assets_tags STRING,\n",
        "    award STRING,\n",
        "    contact STRING,\n",
        "    division STRING,\n",
        "    effective_date DATE,\n",
        "    event STRING,\n",
        "    financing_type STRING,\n",
        "    financing_type_normalized STRING,\n",
        "    financing_type_tags STRING,\n",
        "    headcount FLOAT64,\n",
        "    job_title STRING,\n",
        "    job_title_tags STRING,\n",
        "    location STRING,\n",
        "    location_data STRING,\n",
        "    product STRING,\n",
        "    product_full_text STRING,\n",
        "    product_name STRING,\n",
        "    product_release_type STRING,\n",
        "    product_release_version STRING,\n",
        "    product_fuzzy_match STRING,\n",
        "    product_tags STRING,\n",
        "    recognization STRING,\n",
        "    vulnerability STRING,\n",
        "    relationship_company1_id STRING,\n",
        "    relationship_company1_type STRING,\n",
        "    relationship_most_relevant_id STRING,\n",
        "    relationship_most_relevant_type STRING,\n",
        "    relationship_company2_id STRING,\n",
        "    relationship_company2_type STRING\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "result = client.query(query3).to_dataframe()"
      ],
      "metadata": {
        "id": "KCN4oZ5zBW8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Declaring project name and dataset id\n",
        "project_id = \"pran-project-470608\"\n",
        "dataset_id = \"firmable\""
      ],
      "metadata": {
        "id": "EkryWT7ABpmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ingestion thr data to database\n",
        "df_data.to_gbq(destination_table  = f\"{dataset_id}.data_quality_error_report\",\n",
        "          project_id = project_id,\n",
        "          if_exists=\"append\",   # options: 'fail', 'replace', 'append'\n",
        "          )\n",
        "print(f\"data inserted succesfully to data_table\")"
      ],
      "metadata": {
        "id": "pimwAUBiSFay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_company_details.to_gbq(destination_table  = f\"{project_id}.{dataset_id}.company_details\",\n",
        "          project_id = project_id,\n",
        "          if_exists=\"append\",   # options: 'fail', 'replace', 'append'\n",
        "          )\n",
        "print(f\"data inserted succesfully to company_details\")"
      ],
      "metadata": {
        "id": "r0gDUlKIRgWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_details.to_gbq(destination_table  = f\"{project_id}.{dataset_id}.article_details\",\n",
        "          project_id = project_id,\n",
        "          if_exists=\"append\",   # options: 'fail', 'replace', 'append'\n",
        "          )\n",
        "print(f\"data inserted succesfully to article_details\")"
      ],
      "metadata": {
        "id": "iUubXLI0Ta3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oK89Ow1IWEcV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}